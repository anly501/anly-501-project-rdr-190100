{"cells":[{"cell_type":"raw","metadata":{},"source":["---\n","title: \"Twitter Data Gathering\"\n","author: \"Ramdayal Rewaria\"\n","format:\n","  html:\n","    code-fold: true\n","    theme: darkly\n","---"]},{"cell_type":"markdown","metadata":{},"source":["# Data Gathering\n","\n","- Data Gathering and Pre-Processing is a very important step in any Data science project pipeline. It is undeniable that 80% of a data scientist's time and effort is spent in collecting, cleaning and preparing the data for analysis because datasets come in various sizes and are different in nature. It is extremely important for a data scientist to reshape and refine the datasets into usable datasets, which can be leveraged for analytics.\n","- Knowledge is power, information is knowledge, and data is information in digitized form, at least as defined in IT. Hence, data is power. But before you can leverage that data into a successful strategy for your organization or business, you need to gather it. That’s your first step.\n","- Before we define what is data collection, it’s essential to ask the question, “What is data?” The abridged answer is, data is various kinds of information formatted in a particular way. Therefore, data collection is the process of gathering, measuring, and analyzing accurate data from a variety of relevant sources to find answers to research problems, answer questions, evaluate outcomes, and forecast trends and probabilities.\n","- Our society is highly dependent on data, which underscores the importance of collecting it. Accurate data collection is necessary to make informed business decisions, ensure quality assurance, and keep research integrity.\n","- During data collection, the researchers must identify the data types, the sources of data, and what methods are being used. We will soon see that there are many different data collection methods. There is heavy reliance on data collection in research, commercial, and government fields.\n","- `Why Do We Need Data Collection?`\n","    - Before a judge makes a ruling in a court case or a general creates a plan of attack, they must have as many relevant facts as possible. The best courses of action come from informed decisions, and information and data are synonymous.\n","    - The concept of data collection isn’t a new one but the world has changed. There is far more data available today, and it exists in forms that were unheard of a century ago. The data collection process has had to change and grow with the times, keeping pace with technology.\n","    - Whether you’re in the world of academia, trying to conduct research, or part of the commercial sector, thinking of how to promote a new product, you need data collection to help you make better choices.\n","- `What Are the Different Methods of Data Collection?`\n","    - Surveys\n","    - Transactional Tracking\n","    - Interviews and Focus Groups\n","    - Observation\n","    - Online Tracking\n","    - Forms\n","    - Social Media Monitoring\n","    - Application Programming Interface"]},{"cell_type":"markdown","metadata":{},"source":["# Twitter API\n","- Twitter is what’s happening in the world and what people are talking about right now. You can access Twitter via the web or your mobile device. To share information on Twitter as widely as possible, we also provide companies, developers, and users with programmatic access to Twitter data through our APIs (application programming interfaces).\n","- At the end of 2020, Twitter introduced a new Twitter API built from the ground up. Twitter API v2 comes with more features and data you can pull and analyze, new endpoints, and a lot of functionalities.\n","- With the introduction of that new API, Twitter also introduced a new powerful free product for academics: The Academic Research product track.\n","- The track grants free access to full-archive search and other v2 endpoints, with a volume cap of 10,000,000 tweets per month! If you want to know if you qualify for the track or not, check this link.\n","- Yet since v2 of the API is fairly new, fewer resources exist if you run into issues through the process of collecting data for your research.\n","- Twitter data is unique from data shared by most other social platforms because it reflects information that users choose to share publicly. The API platform provides broad access to public Twitter data that users have chosen to share with the world. It also support APIs that allow users to manage their own non-public Twitter information (e.g., Direct Messages) and provide this information to developers whom they have authorized to do so. "]},{"cell_type":"markdown","metadata":{},"source":["# Import Libraries\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import os\n","import time\n","import requests\n","import json\n","import csv\n","from tqdm import tqdm\n","\n","import tweepy\n","\n","import requests\n","import pandas as pd\n","import os\n","\n","import matplotlib.pyplot as plt\n","from turtle import color\n","from collections import Counter\n"]},{"cell_type":"markdown","metadata":{},"source":["# Set Twitter API Keys"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["consumer_key        = 'TGknXGDLF6fEbV58TN9FhZbxM'\n","consumer_secret     = 'z4zzWXeAEbb9qyKmUUC5Xnz8zLFhRfISxJ9Y4FSAzwyXeC5YI9'\n","access_token        = '1567741611135717376-zV7iig0s4w338wBm40bKP9f9U5PcD3'\n","access_token_secret = 'XC1LDChPSXbyYY4cWmj50QIhP5fMVouGp9FCOF0KSnmIz'\n","bearer_token        = 'AAAAAAAAAAAAAAAAAAAAAOJigwEAAAAABJ%2FEkkSNtKUorB8KrLpPbwIK18I%3DAVPH1a4Kukc6Hbu2JwOPpiTcUtwthDZpJ46iprRgYER8n6PJTw'"]},{"cell_type":"markdown","metadata":{},"source":["# Set the Twitter authentication and bearer token"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n","auth.set_access_token(access_token, access_token_secret)\n","\n","api = tweepy.API(auth, wait_on_rate_limit=True)\n","headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}"]},{"cell_type":"markdown","metadata":{},"source":["Extraction function"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def search_twitter(query, max_results, bearer_token, start_time, end_time, tweet_fields):\n","    \n","    client = tweepy.Client(bearer_token = bearer_token)\n","    tweets = tweepy.Paginator(client.search_recent_tweets, query=query, tweet_fields=tweet_fields,\n","                                start_time=start_time, end_time=end_time).flatten(limit = max_results)\n","    \n","    tweet_search = []\n","    for tweet in tweets:\n","        tweet_search.append((tweet.text, tweet.author_id, tweet.created_at, tweet.lang))\n","        \n","    return tweet_search"]},{"cell_type":"markdown","metadata":{},"source":["Query Parameters"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["query = 'ferrari f1 -is:retweet'\n","max_results = 1000\n","start_time = '2022-09-22T00:00:00Z'\n","end_time = '2022-09-27T00:00:00Z'\n","tweet_fields = 'text,author_id,created_at,lang'\n","\n","search_list = search_twitter(query, max_results, bearer_token, start_time, end_time, tweet_fields)"]},{"cell_type":"markdown","metadata":{},"source":["Storing the tweets to a CSV file"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def store_tweets_f1(query_list):\n","    \n","    max_results = 1000\n","    start_time = '2022-09-22T00:00:00Z'\n","    end_time = '2022-09-27T00:00:00Z'\n","    tweet_fields = 'text,author_id,created_at,lang'\n","    \n","    for query in query_list:\n","        tweet_search = search_twitter(query + \" f1 -is:retweet\", max_results, bearer_token, start_time, end_time, tweet_fields)\n","        df = pd.DataFrame(tweet_search, columns = ['text', 'author_id', 'created_at', 'lang'])\n","        df = df[df['lang'] == 'en']\n","        df = df[['text', 'lang']]\n","        df.to_csv('../../data/00-raw-data/' + query + '_f1_tweets.csv')\n","        \n","    return df"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["query_list = ['ferrari', 'mercedes', 'redbull', 'mclaren', 'aston martin', 'alpha tauri', 'alpine', 'williams', 'haas', 'alfa romeo']"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>lang</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6</th>\n","      <td>The only non-qualifier for the race was Franco...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>IM RACING AGAIN! This time in a new league cal...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>@l4ndoslove color: yellow\\nweather: sunny\\ndri...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>@Leah5899_ Color: yellow\\nWeather: spring suns...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>@stella__f1 @estesunnies you fine with alfa ro...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>348</th>\n","      <td>F1: Zhou admits 2023 race seat ‘not decided ye...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>349</th>\n","      <td>Alfa Romeo and Haas are the only 2 F1 teams th...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>352</th>\n","      <td>Alfa Romeo must have the best value for money ...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>356</th>\n","      <td>Alpine, Alfa Romeo, Williams and Haas all have...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>357</th>\n","      <td>Zhou admits Alfa Romeo 2023 race seat extensio...</td>\n","      <td>en</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>180 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                  text lang\n","6    The only non-qualifier for the race was Franco...   en\n","12   IM RACING AGAIN! This time in a new league cal...   en\n","19   @l4ndoslove color: yellow\\nweather: sunny\\ndri...   en\n","20   @Leah5899_ Color: yellow\\nWeather: spring suns...   en\n","21   @stella__f1 @estesunnies you fine with alfa ro...   en\n","..                                                 ...  ...\n","348  F1: Zhou admits 2023 race seat ‘not decided ye...   en\n","349  Alfa Romeo and Haas are the only 2 F1 teams th...   en\n","352  Alfa Romeo must have the best value for money ...   en\n","356  Alpine, Alfa Romeo, Williams and Haas all have...   en\n","357  Zhou admits Alfa Romeo 2023 race seat extensio...   en\n","\n","[180 rows x 2 columns]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["store_tweets_f1(query_list)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 ('ANLY501')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"a3560e811cddd8e9b8e26d46e82b5ebd764d1b61f7e9403d6fcc054dbf5a890c"}}},"nbformat":4,"nbformat_minor":2}
