<!DOCTYPE html>
<html>
<head><meta charset="utf-8">
	<title>501 project</title>
	<!-- point to css stylesheet -->
	<link href="styles.css" rel="stylesheet" />
</head>

<body>
	<a href="https://analytics.georgetown.edu/"><img src="https://ngpardeshi.georgetown.domains/ANLY 501 IMAGES/DSA.jpg" style="width:600px;height:200px;" /> 
	   <img src="https://ngpardeshi.georgetown.domains/ANLY 501 IMAGES/GU_Background.png" style="width:700px;height:200px;" align="right">
	</a> 
<ul><!-- link back to homepage -->
	<li><a href="https://ramdayal.georgetown.domains/501-project-website/index.html">About me</a></li>
	<!-- tab with dropdown  -->
	<li class="dropdown"><a class="dropbtn" href="javascript:void(0)">Code</a>
	<div class="dropdown-content"><!-- open in new tab use:   <a href="https://www.google.com/" target="_blank">google</a>--><!-- open in same tab use:  <a href="https://www.google.com/">google</a>--><a href="https://github.com/anly501/anly-501-project-rdr-190100" target="_blank">Github</a></div>
	</li>
	<!-- tab with dropdown  -->
	<li class="dropdown"><a class="dropbtn" href="javascript:void(0)">Data</a>
	<div class="dropdown-content"><!-- open in new tab use:   <a href="https://www.google.com/" target="_blank">google</a>--><!-- open in same tab use:  <a href="https://www.google.com/">google</a>--><a href="https://github.com/anly501/anly-501-project-rdr-190100/tree/main/data" target="_blank">Data Files</a></div>
	</li>
	<!-- tab without dropdown  -->
	<li><a href="https://ramdayal.georgetown.domains/501-project-website/pages/introduction.html">Introduction</a></li>
	<!-- tab without dropdown  -->
	<li><a href="https://ramdayal.georgetown.domains/501-project-website/pages/data_gathering.html">Data Gathering</a></li>
	<!-- tab without dropdown  -->
	<li><a href="https://ramdayal.georgetown.domains/501-project-website/pages/data_cleaning.html">Data Cleaning</a></li>
	<!-- tab without dropdown  -->
	<li><a href="https://ramdayal.georgetown.domains/501-project-website/pages/exploring_data.html">Exploring Data</a></li>
	<!-- tab without dropdown  -->
	<li><a href="https://ramdayal.georgetown.domains/501-project-website/pages/naive_bayes.html">Naive Bayes</a></li>
	<!-- tab without dropdown  -->
	<li><a href="https://ramdayal.georgetown.domains/501-project-website/pages/Decision-Trees.html">Decision Trees</a></li>
	<!-- tab without dropdown  -->
	<li><a href="https://ramdayal.georgetown.domains/501-project-website/pages/SVM-Record-data.html">SVM</a></li>
	<!-- tab without dropdown  -->
	<li><a href="https://ramdayal.georgetown.domains/501-project-website/pages/clustering.html">Clustering</a></li>
	<!-- tab without dropdown  -->
	<li><a href="https://ramdayal.georgetown.domains/501-project-website/pages/arm_and_networking.html">ARM and Networking</a></li>
	<!-- tab without dropdown  -->
	<li><a href="https://ramdayal.georgetown.domains/501-project-website/pages/conclusions.html">Conclusion</a></li>
</ul>

<table style = "border: 1px solid black">
    <!--TABLE ROW-1-->
   <tr style = "border: 1px solid black">
      <!--ROW-1 COL-1-->
      <td style = "border: 1px solid black">
            <img src="https://ramdayal.georgetown.domains/501-project-website/images/naivebayes_info.png" style = "width:800px; height:400px">
      </td>
      
      <!--ROW-1 COL-2-->
      <td style = "border: 1px solid black"> <p><b>Information about Naive Bayes</b></p>
        
        <p  style="font-size: 22px;">It is a classification technique based on Bayes’ Theorem with an assumption of independence among predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.</p>
        <p>There are three types of Naive Bayes model</p>
        <p>- Gaussian: It is used in classification and it assumes that features follow a normal distribution.</p>
        <p>- Multinomial: It is used for discrete counts.</p>
        <p>- Bernoulli: The binomial model is useful if your feature vectors are binary (i.e. zeros and ones).</p>
      </td>
	
    </tr>
    <!--TABLE ROW-1--> 

   <tr style = "border: 1px solid black">
	<!--ROW-1 COL-1-->
	<td style = "border: 1px solid black">
		  <img src="https://ramdayal.georgetown.domains/501-project-website/images/naivebayes_info2.png" style = "width:800px; height:400px">
	</td>
	
	<!--ROW-1 COL-2-->
	<td style = "border: 1px solid black"><p><b>Bayes' Theorem</b></p>
	  
	  <p  style="font-size: 18px;">In probability theory and statistics, Bayes' theorem (alternatively Bayes' law or Bayes' rule), named after Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if the risk of developing health problems is known to increase with age, Bayes' theorem allows the risk to an individual of a known age to be assessed more accurately (by conditioning it on their age) than simply assuming that the individual is typical of the population as a whole.</p>
	</td> 
	</tr> 

	 <tr style = "border: 1px solid black">
		<td style = "border: 1px solid black">
			<table>
				<tr>
					<img src="https://ramdayal.georgetown.domains/501-project-website/images/tweet_data_NB.png" style = "width:800px; height:400px">
				</tr>

                <tr>
					<img src="https://ramdayal.georgetown.domains/501-project-website/images/Number of Tweets per Team.png" style = "width:800px; height:400px">
				</tr>
	
			</table>

		</td>

		<!--ROW-1 COL-2-->
		<td style = "border: 1px solid black">
            <p><b>Twitter Data</b></p>
            <p><b>The Dataset</b></p>
		  
		  <p  style="font-size: 22px;">Twitter Text Data consists of 10 labels which correspond to the current teams in Formula 1. Of those 10 teams each, there are a number of tweets in the past 7 days. My goal for this section is to analyse those tweets with the help of Count Vectorizer and create a Multinomial Naive Bayes Classification model to classify a particular tweet into one of these 10 teams.</p>
          <p>Distribution of Label as shown in graph on the right is:</p>
          <p>- Williams: 574</p>
          <p>- Mclaren: 550</p>
          <p>- Mercedes: 534</p>
          <p>- Alpine: 523</p>
          <p>- Ferrari: 453</p>
          <p>- Haas: 419</p>
          <p>- Redbull: 322</p>
          <p>- Aston Martin: 267</p>
          <p>- Alfa Romeo: 180</p>
          <p>Alpha Tauri: 106</p>

		  <a href="https://ramdayal.georgetown.domains/501-project-website/pages/Naive-Bayes-twitterdata.html">Python Code HTML</a>
		  <a href="https://github.com/anly501/anly-501-project-rdr-190100/blob/main/data/01-modified-data/all_teams_sentiment_df.csv">Complete CSV File</a>

        </td>
	 </tr>


	 <tr style = "border: 1px solid black">
		<td style = "border: 1px solid black">
			<table>
                <tr>
                    <td>
                        <img src="https://ramdayal.georgetown.domains/501-project-website/images/naivebayes_code.png" style = "width:400px; height:300px">
                    </td>
            
                    <td>
                        <img src="https://ramdayal.georgetown.domains/501-project-website/images/Confusion Matrix for Model 1.png" style = "width:400px; height:300px">
                    </td>
                </tr>
				<tr>
                    <td>
                        <img src="https://ramdayal.georgetown.domains/501-project-website/images/Confusion Matrix for Model 2.png" style = "width:400px; height:300px">
                    </td>
            
                    <td>
                        <img src="https://ramdayal.georgetown.domains/501-project-website/images/Confusion Matrix for Model 3.png" style = "width:400px; height:300px">
                    </td>
                </tr>
	
			</table>

		</td>
		
		<!--ROW-1 COL-2-->
		<td style = "border: 1px solid black">
            <p><b>Twitter Data</b></p>
            <p><b>Multinomial Naive Bayes' Model</b></p>
		  
		  <p  style="font-size: 24px;">Multinomial Naive Bayes algorithm is a probabilistic learning method that is mostly used in Natural Language Processing (NLP). The algorithm is based on the Bayes theorem and predicts the tag of a text such as a piece of email or newspaper article. It calculates the probability of each tag for a given sample and then gives the tag with the highest probability as output.</p>
          <p>I have created 3 models with alpha as 1, 5, 10. The accuracy is 70%, 75% and 76%.</p>

		  <a href="https://ramdayal.georgetown.domains/501-project-website/pages/Naive-Bayes-twitterdata.html">Python Code HTML</a>
		  <a href="https://github.com/anly501/anly-501-project-rdr-190100/blob/main/data/01-modified-data/all_teams_sentiment_df.csv">Complete CSV File</a>

		</td> 
	 </tr>


	 <tr style = "border: 1px solid black">
		<td style = "border: 1px solid black">
			<table>
				<tr>
					<img src="https://ramdayal.georgetown.domains/501-project-website/images/race_data_cleaned_final.png" style = "width:800px; height:400px">
				</tr>

                <tr>
					<img src="https://ramdayal.georgetown.domains/501-project-website/images/label_dist_R.png" style = "width:800px; height:400px">
				</tr>
	
			</table>

		</td>

		<!--ROW-1 COL-2-->
		<td style = "border: 1px solid black">
            <p><b>Record Dataset</b></p>
            <p><b>The Dataset</b></p>
		  
		  <p  style="font-size: 24px;">The labelled record dataset has 19 columns with 18 features and 1 label column. Some of the feature variables include: Id of the race, Position finished, Laps completed, Cumulative points/wins/laps and so on. Our labels are Podium, Top_10, Outside_Top_10 finishes. I am using Naive Bayes in R to predict that given the feature variables, if a driver will finish in Top 3 (Podium), Top 10 or Outside Top 10.</p>
          <p>Distribution of Label as shown in graph on the right is:</p>
          <p>- Podium: 3439</p>
          <p>- Top_10: 7978</p>
          <p>- OutsideTop_10: 15524</p>

		  <a href="https://ramdayal.georgetown.domains/501-project-website/pages/Naive-Bayes-recorddata.html">R Code HTML</a>
		  <a href="https://github.com/anly501/anly-501-project-rdr-190100/blob/main/data/00-raw-data/data_cleaned.csv">Complete CSV File</a>

		</td> 
	 </tr>

     <tr style = "border: 1px solid black">
		<td style = "border: 1px solid black">
			<table>
                <tr>
                    <td>
                        <img src="https://ramdayal.georgetown.domains/501-project-website/images/NB-traincm-R.png" style = "width:400px; height:300px">
                    </td>
            
                    <td>
                        <img src="https://ramdayal.georgetown.domains/501-project-website/images/NB-traincm-R-heat.png" style = "width:400px; height:300px">
                    </td>
                </tr>
				<tr>
                    <td>
                        <img src="https://ramdayal.georgetown.domains/501-project-website/images/NB-testcm-R.png" style = "width:400px; height:300px">
                    </td>
            
                    <td>
                        <img src="https://ramdayal.georgetown.domains/501-project-website/images/NB-testcm-R-heat.png" style = "width:400px; height:300px">
                    </td>
                </tr>
	
			</table>

		</td>
		
		<!--ROW-1 COL-2-->
		<td style = "border: 1px solid black">
            <p><b>Record Dataset</b></p>
            <p><b>Naive Bayes' Model in R on Record Dataset</b></p>
		  
		  <p  style="font-size: 24px;">Naive Bayes is a Supervised Non-linear classification algorithm in R Programming. Naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Baye’s theorem with strong(Naive) independence assumptions between the features or variables. The Naive Bayes algorithm is called “Naive” because it makes the assumption that the occurrence of a certain feature is independent of the occurrence of other features.</p>
          <p>I have created 1 model with training accuracy as 83.93% and testing accuracy as 83.24%.</p>
          <p>Some interesting statistics according to me from the model are:</p>
          <p>- Drivers are more likely to get a Podium (Top 3) if their Cumulative points in their career (till race date) are greater than 410.</p>
          <p>- Drivers are more likely to get a Podium (Top 3) if their Cumulative laps completed in their career (till race date) are greater than 4400.</p>
          <p>- Drivers are more likely to get a Podium (Top 3) if their Cumulative pole finishes (1st in Qualifying) in their career (till race date) are greater than 12.</p>
          <p>- Drivers are more likely to get a Podium (Top 3) if their Cumulative wins (1st position) in their career (till race date) are greater than 16.</p>


		  <a href="https://ramdayal.georgetown.domains/501-project-website/pages/Naive-Bayes-recorddata.html">R Code HTML</a>
		  <a href="https://github.com/anly501/anly-501-project-rdr-190100/blob/main/data/00-raw-data/data_cleaned.csv">Complete CSV File</a>

		</td> 
	 </tr>


</table>
</body>
</html>